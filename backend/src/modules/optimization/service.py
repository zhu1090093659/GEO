"""
Optimization Module - Business Logic Service

Handles optimization recommendations generation
and llms.txt file creation using database storage.
"""
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import json
from urllib.parse import urlparse

from sqlalchemy import select, func, desc, and_
from sqlalchemy.ext.asyncio import AsyncSession

from .models import (
    Recommendation, LlmsTxtResult, OptimizationStats,
    RecommendationCategory, RecommendationPriority,
    RecommendationEffort, RecommendationStatus
)
from .schemas import (
    RecommendationsResponse,
    RecommendationItem,
    RecommendationSummary,
    LlmsTxtResponse,
    LlmsTxtSection,
    OptimizationStatsResponse,
)

# Import for data-driven recommendations
from src.modules.tracking.models import Brand, VisibilityScore, BrandMention


def normalize_name(name: str) -> str:
    """Normalize brand/domain name for consistent matching."""
    return name.lower().strip()


def extract_domain(url: str) -> str:
    """Extract domain from URL."""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc or url
        if domain.startswith('www.'):
            domain = domain[4:]
        return domain.lower()
    except Exception:
        return url.lower()


# llms.txt template
LLMS_TXT_TEMPLATE = """# {site_name}

> {description}

## About

{about}

## Main Sections

{sections}

## Key Topics

{topics}

## Contact

- Website: {url}
{contact}

---

*Generated by GEO - Generative Engine Optimization*
*Last updated: {timestamp}*
"""


# Recommendation templates based on common optimization patterns
RECOMMENDATION_TEMPLATES = [
    {
        "category": RecommendationCategory.CONTENT.value,
        "priority": RecommendationPriority.P0.value,
        "title": "Create Comprehensive FAQ Section",
        "description": "FAQs closely match how users query AI assistants. Create content that directly answers common questions about your brand.",
        "action_steps": [
            "Identify top queries related to your brand from Topic Discovery",
            "Create detailed answers for each question (150-300 words)",
            "Use natural language that AI can easily extract",
            "Add FAQ schema markup for better AI understanding",
            "Update FAQ regularly based on new query trends"
        ],
        "expected_impact": "15-25% improvement in AI citation rate",
        "effort": RecommendationEffort.LOW.value,
        "impact_score": 85.0,
        "condition": lambda data: data.get("has_low_visibility", True),
    },
    {
        "category": RecommendationCategory.TECHNICAL.value,
        "priority": RecommendationPriority.P0.value,
        "title": "Deploy llms.txt File",
        "description": "Create and deploy llms.txt to help AI assistants better understand and index your content. This emerging standard improves AI discoverability.",
        "action_steps": [
            "Use GEO llms.txt generator to create the file",
            "Review and customize the generated content",
            "Deploy to your website root (/llms.txt)",
            "Add sitemap reference for AI crawlers",
            "Keep updated as content changes"
        ],
        "expected_impact": "20-35% improvement in AI discoverability",
        "effort": RecommendationEffort.LOW.value,
        "impact_score": 90.0,
        "condition": lambda data: True,  # Always recommend
    },
    {
        "category": RecommendationCategory.STRUCTURE.value,
        "priority": RecommendationPriority.P0.value,
        "title": "Implement Schema.org Markup",
        "description": "Structured data helps AI understand your content context and relationships. This is critical for accurate AI citations.",
        "action_steps": [
            "Add Organization schema to homepage",
            "Add Product/Service schema to relevant pages",
            "Add FAQ schema to FAQ pages",
            "Add Article schema to blog posts",
            "Validate markup with Google's testing tool"
        ],
        "expected_impact": "10-20% improvement in structured citations",
        "effort": RecommendationEffort.MEDIUM.value,
        "impact_score": 80.0,
        "condition": lambda data: True,
    },
    {
        "category": RecommendationCategory.CONTENT.value,
        "priority": RecommendationPriority.P0.value,
        "title": "Improve Product/Service Descriptions",
        "description": "AI assistants often cite detailed product descriptions. Enhance your pages with comprehensive, factual information.",
        "action_steps": [
            "Review current descriptions for completeness",
            "Add specific features, specifications, and use cases",
            "Include comparison points with alternatives",
            "Add pricing information where applicable",
            "Use clear, factual language"
        ],
        "expected_impact": "15-20% improvement in visibility score",
        "effort": RecommendationEffort.MEDIUM.value,
        "impact_score": 75.0,
        "condition": lambda data: True,
    },
    {
        "category": RecommendationCategory.CONTENT.value,
        "priority": RecommendationPriority.P1.value,
        "title": "Publish Authoritative Content",
        "description": "Create expert content that AI assistants are more likely to cite as authoritative sources.",
        "action_steps": [
            "Identify topics where you have unique expertise",
            "Create in-depth guides and tutorials",
            "Include data, research, and citations",
            "Feature expert authors with credentials",
            "Keep content updated and accurate"
        ],
        "expected_impact": "Long-term authority building, 10-30% citation increase",
        "effort": RecommendationEffort.HIGH.value,
        "impact_score": 70.0,
        "condition": lambda data: True,
    },
    {
        "category": RecommendationCategory.SEO.value,
        "priority": RecommendationPriority.P1.value,
        "title": "Build Domain Authority",
        "description": "AI systems consider domain authority when selecting sources to cite. Focus on building your domain's reputation.",
        "action_steps": [
            "Earn backlinks from reputable industry sources",
            "Get featured in industry publications",
            "Build social proof and testimonials",
            "Maintain consistent content publishing",
            "Engage with industry communities"
        ],
        "expected_impact": "Long-term visibility improvement",
        "effort": RecommendationEffort.HIGH.value,
        "impact_score": 65.0,
        "condition": lambda data: data.get("low_authority", False),
    },
    {
        "category": RecommendationCategory.BRANDING.value,
        "priority": RecommendationPriority.P1.value,
        "title": "Improve Brand Sentiment",
        "description": "AI systems tend to recommend brands with positive sentiment. Address negative mentions and build positive presence.",
        "action_steps": [
            "Monitor brand mentions using GEO tracking",
            "Address negative reviews and feedback promptly",
            "Encourage positive customer reviews",
            "Create case studies showcasing success",
            "Engage positively on social platforms"
        ],
        "expected_impact": "Sentiment improvement leads to better recommendations",
        "effort": RecommendationEffort.MEDIUM.value,
        "impact_score": 60.0,
        "condition": lambda data: data.get("negative_sentiment", False),
    },
    {
        "category": RecommendationCategory.TECHNICAL.value,
        "priority": RecommendationPriority.P1.value,
        "title": "Optimize for AI Crawlers",
        "description": "Ensure AI systems can effectively crawl and understand your website content.",
        "action_steps": [
            "Ensure robots.txt allows AI crawlers",
            "Add XML sitemap with all important pages",
            "Improve page load speed",
            "Use semantic HTML structure",
            "Add proper heading hierarchy (H1-H6)"
        ],
        "expected_impact": "Better AI indexing and understanding",
        "effort": RecommendationEffort.MEDIUM.value,
        "impact_score": 55.0,
        "condition": lambda data: True,
    },
]


class OptimizationService:
    """Service for optimization recommendations and llms.txt generation."""
    
    # ========================================
    # Recommendations
    # ========================================
    
    async def generate_recommendations(
        self,
        db: AsyncSession,
        brand: str,
        focus_areas: Optional[List[str]] = None,
        include_completed: bool = False,
    ) -> RecommendationsResponse:
        """
        Generate optimization recommendations for a brand.
        
        Uses tracking data to create intelligent, data-driven recommendations.
        
        Args:
            db: Database session
            brand: Brand name
            focus_areas: Optional filter by category
            include_completed: Include completed recommendations
            
        Returns:
            Generated recommendations with summary
        """
        brand_normalized = normalize_name(brand)
        
        # Gather brand data for intelligent recommendations
        brand_data = await self._gather_brand_data(db, brand_normalized)
        
        # Get existing recommendations for this brand
        existing_query = select(Recommendation).where(
            Recommendation.brand_normalized == brand_normalized
        )
        if not include_completed:
            existing_query = existing_query.where(
                Recommendation.status != RecommendationStatus.COMPLETED.value
            )
        existing_result = await db.execute(existing_query)
        existing_recs = existing_result.scalars().all()
        existing_titles = {r.title for r in existing_recs}
        
        # Generate new recommendations based on templates
        new_recs: List[Recommendation] = []
        for template in RECOMMENDATION_TEMPLATES:
            # Check if already exists
            if template["title"] in existing_titles:
                continue
            
            # Check condition
            if not template["condition"](brand_data):
                continue
            
            # Filter by focus areas
            if focus_areas and template["category"] not in focus_areas:
                continue
            
            # Create recommendation
            rec = Recommendation(
                brand=brand,
                brand_normalized=brand_normalized,
                category=template["category"],
                priority=template["priority"],
                title=template["title"],
                description=template["description"],
                action_steps_json=json.dumps(template["action_steps"]),
                expected_impact=template["expected_impact"],
                effort=template["effort"],
                impact_score=template["impact_score"],
                data_source_json=json.dumps(brand_data),
            )
            db.add(rec)
            new_recs.append(rec)
        
        await db.commit()
        
        # Refresh to get IDs
        for rec in new_recs:
            await db.refresh(rec)
        
        # Combine all recommendations
        all_recs = list(existing_recs) + new_recs
        
        # Sort by priority and impact
        priority_order = {"P0": 0, "P1": 1, "P2": 2}
        all_recs.sort(key=lambda r: (priority_order.get(r.priority, 3), -r.impact_score))
        
        # Build summary
        summary = RecommendationSummary(
            total=len(all_recs),
            by_priority={
                "P0": sum(1 for r in all_recs if r.priority == "P0"),
                "P1": sum(1 for r in all_recs if r.priority == "P1"),
                "P2": sum(1 for r in all_recs if r.priority == "P2"),
            },
            by_category={
                "content": sum(1 for r in all_recs if r.category == "content"),
                "structure": sum(1 for r in all_recs if r.category == "structure"),
                "technical": sum(1 for r in all_recs if r.category == "technical"),
                "seo": sum(1 for r in all_recs if r.category == "seo"),
                "branding": sum(1 for r in all_recs if r.category == "branding"),
            },
            by_status={
                "pending": sum(1 for r in all_recs if r.status == "pending"),
                "in_progress": sum(1 for r in all_recs if r.status == "in_progress"),
                "completed": sum(1 for r in all_recs if r.status == "completed"),
                "dismissed": sum(1 for r in all_recs if r.status == "dismissed"),
            },
            avg_impact_score=sum(r.impact_score for r in all_recs) / len(all_recs) if all_recs else 0,
        )
        
        return RecommendationsResponse(
            brand=brand,
            generated_at=datetime.utcnow(),
            recommendations=[
                RecommendationItem(
                    id=r.id,
                    brand=r.brand,
                    category=r.category,
                    priority=r.priority,
                    title=r.title,
                    description=r.description,
                    action_steps=json.loads(r.action_steps_json) if r.action_steps_json else [],
                    expected_impact=r.expected_impact,
                    effort=r.effort,
                    impact_score=r.impact_score,
                    status=r.status,
                    created_at=r.created_at,
                    updated_at=r.updated_at,
                    completed_at=r.completed_at,
                )
                for r in all_recs
            ],
            summary=summary,
            new_count=len(new_recs),
        )
    
    async def _gather_brand_data(
        self,
        db: AsyncSession,
        brand_normalized: str,
    ) -> Dict[str, Any]:
        """Gather brand data for intelligent recommendation generation."""
        data = {
            "has_low_visibility": True,
            "low_authority": False,
            "negative_sentiment": False,
            "visibility_score": 0,
            "mention_count": 0,
            "avg_sentiment": 0,
        }
        
        # Get visibility score
        score_result = await db.execute(
            select(VisibilityScore)
            .where(VisibilityScore.brand_normalized == brand_normalized)
            .order_by(desc(VisibilityScore.date))
            .limit(1)
        )
        latest_score = score_result.scalar_one_or_none()
        
        if latest_score:
            data["visibility_score"] = latest_score.score
            data["has_low_visibility"] = latest_score.score < 50
            data["mention_count"] = latest_score.mention_count
            data["avg_sentiment"] = latest_score.avg_sentiment
            data["negative_sentiment"] = latest_score.avg_sentiment < -0.2
        
        # Check if brand exists
        brand_result = await db.execute(
            select(Brand).where(Brand.normalized_name == brand_normalized)
        )
        brand = brand_result.scalar_one_or_none()
        
        if not brand:
            data["low_authority"] = True
        
        return data
    
    async def get_recommendations(
        self,
        db: AsyncSession,
        brand: str,
        status: Optional[str] = None,
        category: Optional[str] = None,
    ) -> List[RecommendationItem]:
        """Get existing recommendations for a brand."""
        brand_normalized = normalize_name(brand)
        
        query = select(Recommendation).where(
            Recommendation.brand_normalized == brand_normalized
        ).order_by(Recommendation.priority, desc(Recommendation.impact_score))
        
        if status:
            query = query.where(Recommendation.status == status)
        if category:
            query = query.where(Recommendation.category == category)
        
        result = await db.execute(query)
        recs = result.scalars().all()
        
        return [
            RecommendationItem(
                id=r.id,
                brand=r.brand,
                category=r.category,
                priority=r.priority,
                title=r.title,
                description=r.description,
                action_steps=json.loads(r.action_steps_json) if r.action_steps_json else [],
                expected_impact=r.expected_impact,
                effort=r.effort,
                impact_score=r.impact_score,
                status=r.status,
                created_at=r.created_at,
                updated_at=r.updated_at,
                completed_at=r.completed_at,
            )
            for r in recs
        ]
    
    async def update_recommendation_status(
        self,
        db: AsyncSession,
        recommendation_id: int,
        status: str,
        notes: Optional[str] = None,
    ) -> Optional[RecommendationItem]:
        """Update recommendation status."""
        result = await db.execute(
            select(Recommendation).where(Recommendation.id == recommendation_id)
        )
        rec = result.scalar_one_or_none()
        
        if not rec:
            return None
        
        rec.status = status
        if status == RecommendationStatus.COMPLETED.value:
            rec.completed_at = datetime.utcnow()
        
        await db.commit()
        await db.refresh(rec)
        
        return RecommendationItem(
            id=rec.id,
            brand=rec.brand,
            category=rec.category,
            priority=rec.priority,
            title=rec.title,
            description=rec.description,
            action_steps=json.loads(rec.action_steps_json) if rec.action_steps_json else [],
            expected_impact=rec.expected_impact,
            effort=rec.effort,
            impact_score=rec.impact_score,
            status=rec.status,
            created_at=rec.created_at,
            updated_at=rec.updated_at,
            completed_at=rec.completed_at,
        )
    
    # ========================================
    # llms.txt Generation
    # ========================================
    
    async def generate_llms_txt(
        self,
        db: AsyncSession,
        url: str,
        site_name: str,
        description: Optional[str] = None,
        auto_generate: bool = True,
        sections: Optional[List[Dict[str, str]]] = None,
        topics: Optional[List[str]] = None,
        contact_email: Optional[str] = None,
    ) -> LlmsTxtResponse:
        """
        Generate llms.txt content for a website.
        
        Args:
            db: Database session
            url: Website URL
            site_name: Site/organization name
            description: Optional description
            auto_generate: Whether to auto-discover sections
            sections: Optional predefined sections
            topics: Optional key topics
            contact_email: Optional contact email
            
        Returns:
            Generated llms.txt content
        """
        domain = extract_domain(url)
        
        # Auto-generate description if not provided
        if not description:
            description = f"Official website for {site_name}. Your trusted source for information and resources."
        
        # Generate about section
        about = f"{site_name} provides comprehensive information, resources, and services. We are committed to delivering accurate, helpful content."
        
        # Generate sections
        if sections:
            sections_list = sections
        else:
            # Default sections for auto-generate
            sections_list = [
                {"name": "Home", "path": "/", "description": "Main landing page with overview"},
                {"name": "Products", "path": "/products", "description": "Our product offerings"},
                {"name": "Services", "path": "/services", "description": "Services we provide"},
                {"name": "About", "path": "/about", "description": "About our company"},
                {"name": "Blog", "path": "/blog", "description": "Latest news and insights"},
                {"name": "Contact", "path": "/contact", "description": "Get in touch with us"},
            ]
        
        sections_text = "\n".join([
            f"- [{s.get('name', 'Section')}]({s.get('path', '/')}): {s.get('description', '')}"
            for s in sections_list
        ])
        
        # Generate topics
        if topics:
            topics_text = "\n".join([f"- {t}" for t in topics])
        else:
            topics_text = "- Product information\n- Company updates\n- Industry insights\n- Customer resources"
        
        # Contact info
        contact_text = ""
        if contact_email:
            contact_text = f"- Email: {contact_email}"
        
        # Build content
        content = LLMS_TXT_TEMPLATE.format(
            site_name=site_name,
            description=description,
            about=about,
            sections=sections_text,
            topics=topics_text,
            url=url,
            contact=contact_text,
            timestamp=datetime.utcnow().strftime("%Y-%m-%d"),
        )
        
        # Store result
        result = LlmsTxtResult(
            url=url,
            domain=domain,
            site_name=site_name,
            content=content,
            description=description,
            sections_json=json.dumps(sections_list),
            topics_json=json.dumps(topics) if topics else None,
            contact_info=contact_email,
            auto_generated=auto_generate,
            expires_at=datetime.utcnow() + timedelta(days=30),
        )
        db.add(result)
        await db.commit()
        await db.refresh(result)
        
        return LlmsTxtResponse(
            id=result.id,
            url=result.url,
            domain=result.domain,
            site_name=result.site_name,
            content=result.content,
            sections=[
                LlmsTxtSection(
                    name=s.get("name", ""),
                    path=s.get("path", ""),
                    description=s.get("description", ""),
                )
                for s in sections_list
            ],
            preview_url=f"/api/optimization/llms-txt/{result.id}/preview",
            download_url=f"/api/optimization/llms-txt/{result.id}/download",
            created_at=result.created_at,
        )
    
    async def get_llms_txt(
        self,
        db: AsyncSession,
        result_id: int,
    ) -> Optional[LlmsTxtResult]:
        """Get generated llms.txt by ID."""
        result = await db.execute(
            select(LlmsTxtResult).where(LlmsTxtResult.id == result_id)
        )
        return result.scalar_one_or_none()
    
    # ========================================
    # Statistics
    # ========================================
    
    async def get_stats(self, db: AsyncSession) -> OptimizationStatsResponse:
        """Get optimization module statistics."""
        # Total recommendations
        total_recs = await db.scalar(select(func.count(Recommendation.id))) or 0
        
        # By status
        status_result = await db.execute(
            select(Recommendation.status, func.count(Recommendation.id))
            .group_by(Recommendation.status)
        )
        by_status = {row[0]: row[1] for row in status_result.all()}
        
        # By category
        category_result = await db.execute(
            select(Recommendation.category, func.count(Recommendation.id))
            .group_by(Recommendation.category)
        )
        by_category = {row[0]: row[1] for row in category_result.all()}
        
        # By priority
        priority_result = await db.execute(
            select(Recommendation.priority, func.count(Recommendation.id))
            .group_by(Recommendation.priority)
        )
        by_priority = {row[0]: row[1] for row in priority_result.all()}
        
        # Total llms.txt
        total_llms = await db.scalar(select(func.count(LlmsTxtResult.id))) or 0
        
        # Average impact score
        avg_impact = await db.scalar(
            select(func.avg(Recommendation.impact_score))
        ) or 0.0
        
        # Completion rate
        completed = by_status.get("completed", 0)
        completion_rate = (completed / total_recs * 100) if total_recs > 0 else 0.0
        
        return OptimizationStatsResponse(
            total_recommendations=total_recs,
            recommendations_by_status=by_status,
            recommendations_by_category=by_category,
            recommendations_by_priority=by_priority,
            total_llms_txt_generated=total_llms,
            avg_impact_score=round(avg_impact, 1),
            completion_rate=round(completion_rate, 1),
        )


# Global service instance
optimization_service = OptimizationService()
